{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObieoLqNT0X/D40KLw/ofI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShivM99/Python/blob/main/Titanic_LR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "odlnAFcBzx77"
      },
      "outputs": [],
      "source": [
        "#Importing the training dataset\n",
        "import pandas as pd\n",
        "train = pd.read_csv (r\"titanic_train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Seggregating the features and the target for 'titanic_train'\n",
        "x = train.iloc[:, [2, 4, 5, 6, 7, 9, 11]].values\n",
        "x_df = pd.DataFrame (x, columns = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'])\n",
        "print (\"\\nFeatures:\\n\", x_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yuh80aK01Ap7",
        "outputId": "c0d3edab-5f30-47df-db62-ceeb8c907566"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Features:\n",
            "     Pclass     Sex   Age SibSp Parch     Fare Embarked\n",
            "0        3    male  22.0     1     0     7.25        S\n",
            "1        1  female  38.0     1     0  71.2833        C\n",
            "2        3  female  26.0     0     0    7.925        S\n",
            "3        1  female  35.0     1     0     53.1        S\n",
            "4        3    male  35.0     0     0     8.05        S\n",
            "..     ...     ...   ...   ...   ...      ...      ...\n",
            "886      2    male  27.0     0     0     13.0        S\n",
            "887      1  female  19.0     0     0     30.0        S\n",
            "888      3  female   NaN     1     2    23.45        S\n",
            "889      1    male  26.0     0     0     30.0        C\n",
            "890      3    male  32.0     0     0     7.75        Q\n",
            "\n",
            "[891 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = train.iloc[:, 1].values\n",
        "y_df = pd.DataFrame (y, columns = ['Survived'])\n",
        "print (\"\\nTarget:\\n\", y_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0qleiuy1hHo",
        "outputId": "d1175f1c-97b2-4be3-fabc-112c3b606e11"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Target:\n",
            "      Survived\n",
            "0           0\n",
            "1           1\n",
            "2           1\n",
            "3           1\n",
            "4           0\n",
            "..        ...\n",
            "886         0\n",
            "887         1\n",
            "888         0\n",
            "889         1\n",
            "890         0\n",
            "\n",
            "[891 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling the missing values\n",
        "#One hot encoding the categorical features\n",
        "print (\"\\nMissing values in different features:\\n\", x_df.isnull().sum())\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKl5Ax15z5Jt",
        "outputId": "cb6b620d-023b-40f6-8804-c1c20222044d"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing values in different features:\n",
            " Pclass        0\n",
            "Sex           0\n",
            "Age         177\n",
            "SibSp         0\n",
            "Parch         0\n",
            "Fare          0\n",
            "Embarked      2\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ColumnTransformer (transformers = [(\"name_of_object\", object_creation, [columns]), (\"name_of_object\", object_creation, [columns]), ...], remainder = \"passthrough\")\n",
        "ct = ColumnTransformer (transformers = [(\"si_mode\", SimpleImputer (missing_values = np.nan, strategy = \"most_frequent\"), [2]), (\"si_mean\", SimpleImputer (missing_values = np.nan, strategy = \"mean\"), [-2]),  (\"encoder\", OneHotEncoder(), [0, 1])], remainder = \"passthrough\")\n",
        "x = ct.fit_transform (x)"
      ],
      "metadata": {
        "id": "q8jS0uef18t_"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pipeline (steps = [(\"name_of_object\", object_creation), (\"name_of_object\", object_creation), ...])\n",
        "pipe = Pipeline (steps = [(\"si_mode\", SimpleImputer (missing_values = np.nan, strategy = \"most_frequent\")), (\"encoder\", OneHotEncoder())])\n",
        "embarked = ColumnTransformer (transformers = [(\"pipe\", pipe, [-1])], remainder = \"passthrough\")\n",
        "x = embarked.fit_transform (x)\n",
        "x_df_new = pd.DataFrame (x)\n",
        "print (\"\\nPreprocessed features:\\n\", x_df_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC9LS-WF2C8s",
        "outputId": "9a18a634-1e1a-4452-b14d-81ae7a914422"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Preprocessed features:\n",
            "       0    1    2     3        4    5    6    7    8    9  10 11\n",
            "0    0.0  0.0  1.0  22.0     7.25  0.0  0.0  1.0  0.0  1.0  1  0\n",
            "1    1.0  0.0  0.0  38.0  71.2833  1.0  0.0  0.0  1.0  0.0  1  0\n",
            "2    0.0  0.0  1.0  26.0    7.925  0.0  0.0  1.0  1.0  0.0  0  0\n",
            "3    0.0  0.0  1.0  35.0     53.1  1.0  0.0  0.0  1.0  0.0  1  0\n",
            "4    0.0  0.0  1.0  35.0     8.05  0.0  0.0  1.0  0.0  1.0  0  0\n",
            "..   ...  ...  ...   ...      ...  ...  ...  ...  ...  ... .. ..\n",
            "886  0.0  0.0  1.0  27.0     13.0  0.0  1.0  0.0  0.0  1.0  0  0\n",
            "887  0.0  0.0  1.0  19.0     30.0  1.0  0.0  0.0  1.0  0.0  0  0\n",
            "888  0.0  0.0  1.0  24.0    23.45  0.0  0.0  1.0  1.0  0.0  1  2\n",
            "889  1.0  0.0  0.0  26.0     30.0  1.0  0.0  0.0  0.0  1.0  0  0\n",
            "890  0.0  1.0  0.0  32.0     7.75  0.0  0.0  1.0  0.0  1.0  0  0\n",
            "\n",
            "[891 rows x 12 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the dataset into training & test datasets not done as the dataset is already splitted\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split (x, y, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "kLg1yJZez7C8"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Standardizing the dataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler ()\n",
        "x_train[:, [3, 11]] = sc.fit_transform (x_train[:, [3, 11]])\n",
        "x_test[:, [3, 11]] = sc.transform (x_test[:, [3, 11]])\n",
        "x_train_df = pd.DataFrame (x_train)\n",
        "print (\"\\nStandardised features:\\n\", x_train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Bv79CnRz9EW",
        "outputId": "e5622511-3b88-4e78-e445-6cd712fe3367"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Standardised features:\n",
            "       0    1    2         3        4    5    6    7    8    9  10        11\n",
            "0    1.0  0.0  0.0 -0.346969  15.2458  0.0  0.0  1.0  1.0  0.0  0  1.959264\n",
            "1    0.0  0.0  1.0  0.180174     10.5  0.0  1.0  0.0  0.0  1.0  0  -0.47741\n",
            "2    1.0  0.0  0.0  0.180174  37.0042  0.0  1.0  0.0  0.0  1.0  1  0.740927\n",
            "3    1.0  0.0  0.0 -0.648193   4.0125  0.0  0.0  1.0  0.0  1.0  0  -0.47741\n",
            "4    0.0  0.0  1.0 -0.572887     7.25  0.0  0.0  1.0  0.0  1.0  0  -0.47741\n",
            "..   ...  ...  ...       ...      ...  ...  ...  ...  ...  ... ..       ...\n",
            "707  1.0  0.0  0.0  0.782623  83.1583  1.0  0.0  0.0  1.0  0.0  1  0.740927\n",
            "708  0.0  0.0  1.0 -0.723499   7.8542  0.0  0.0  1.0  1.0  0.0  1  -0.47741\n",
            "709  0.0  1.0  0.0 -0.346969   7.7333  0.0  0.0  1.0  0.0  1.0  0  -0.47741\n",
            "710  0.0  0.0  1.0  0.556705     17.4  0.0  0.0  1.0  1.0  0.0  1  -0.47741\n",
            "711  0.0  0.0  1.0  2.364052     39.0  0.0  1.0  0.0  0.0  1.0  1  0.740927\n",
            "\n",
            "[712 rows x 12 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Building the Logistic Regression model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression (max_iter = 500, random_state = 0)\n",
        "lr.fit (x_train, y_train)\n",
        "y_pred = lr.predict (x_test)"
      ],
      "metadata": {
        "id": "pxpKh7N4z-x1"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the accuracy of Logistic Regression model\n",
        "from sklearn.metrics import accuracy_score\n",
        "print (\"\\nAccuracy of the Logistic Regression model:\", accuracy_score (y_test, y_pred)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjPoc0VW0A-l",
        "outputId": "62b4e4e7-e9c5-4934-e8ca-829e89eabcd8"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy of the Logistic Regression model: 80.44692737430168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cross-validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "accuracies = cross_val_score (estimator = lr, X = x_train, y = y_train, cv = 10)\n",
        "print (\"\\nMean accuracy:\", accuracies.mean()*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mo2GWPKF0DA-",
        "outputId": "18fa247b-38e0-4ee7-f5c8-23f9722f5302"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mean accuracy: 79.36424100156493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Grid search\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "h_parameters = [{\"penalty\": ['l1', 'l2', 'elasticnet', 'none'], \"C\": [0, 0.25, 0.50, 0.75, 1], \"solver\": ['lbfgs', 'liblinear', 'newton-cg', 'sag', 'saga'], \"max_iter\": [100, 1000, 2500, 5000]}]\n",
        "grid = GridSearchCV (estimator = lr, param_grid = h_parameters, scoring = \"accuracy\", n_jobs = -1, cv = 10)\n",
        "grid.fit (x_train, y_train)\n",
        "best_hparameters = grid.best_params_\n",
        "best_accuracy = grid.best_score_\n",
        "print (\"\\nBest hyper-parameters:\\n\", best_hparameters)\n",
        "print (\"\\nBest accuracy:\", best_accuracy*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DrJ5lH10Eoe",
        "outputId": "e9dec3b2-1eab-4965-bf15-2172cc084d79"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "2240 fits failed out of a total of 4000.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "800 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1160, in fit\n",
            "    self._validate_params()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 600, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'C' parameter of LogisticRegression must be a float in the range (0, inf]. Got 0 instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "160 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "160 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "160 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "160 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "160 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 64, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "160 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "160 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "160 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
            "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 1048, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 864, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 782, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 263, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
            "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
            "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "160 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 71, in _check_solver\n",
            "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
            "ValueError: penalty='none' is not supported for the liblinear solver\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.79927621        nan        nan\n",
            " 0.72627152 0.79925665 0.79925665 0.79925665 0.72631064 0.72208529\n",
            "        nan        nan        nan        nan        nan 0.78943662\n",
            "        nan 0.78943662 0.72631064 0.72208529        nan 0.79927621\n",
            "        nan        nan 0.76840767 0.79925665 0.79925665 0.79925665\n",
            " 0.80766823 0.76981612        nan        nan        nan        nan\n",
            "        nan 0.78943662        nan 0.78943662 0.80905712 0.77122457\n",
            "        nan 0.79927621        nan        nan 0.81046557 0.79925665\n",
            " 0.79925665 0.79925665 0.80911581 0.81187402        nan        nan\n",
            "        nan        nan        nan 0.78943662        nan 0.78943662\n",
            " 0.80489045 0.81187402        nan 0.79927621        nan        nan\n",
            " 0.8006651  0.79925665 0.79925665 0.79925665 0.803482   0.81050469\n",
            "        nan        nan        nan        nan        nan 0.78943662\n",
            "        nan 0.78943662 0.803482   0.81050469        nan 0.79364241\n",
            "        nan        nan 0.72488263 0.79643975 0.79643975 0.79643975\n",
            " 0.72631064 0.72208529        nan        nan        nan        nan\n",
            "        nan 0.78943662        nan 0.78943662 0.72631064 0.72208529\n",
            "        nan 0.79364241        nan        nan 0.76981612 0.79643975\n",
            " 0.79643975 0.79643975 0.80905712 0.76981612        nan        nan\n",
            "        nan        nan        nan 0.78943662        nan 0.78943662\n",
            " 0.80905712 0.77122457        nan 0.79364241        nan        nan\n",
            " 0.81046557 0.79643975 0.79643975 0.79643975 0.8062989  0.81187402\n",
            "        nan        nan        nan        nan        nan 0.78943662\n",
            "        nan 0.78943662 0.80489045 0.81187402        nan 0.79364241\n",
            "        nan        nan 0.80911581 0.79643975 0.79643975 0.79643975\n",
            " 0.803482   0.81050469        nan        nan        nan        nan\n",
            "        nan 0.78943662        nan 0.78943662 0.803482   0.81050469\n",
            "        nan 0.79364241        nan        nan 0.72208529 0.79643975\n",
            " 0.79643975 0.79643975 0.72631064 0.72208529        nan        nan\n",
            "        nan        nan        nan 0.78943662        nan 0.78943662\n",
            " 0.72631064 0.72208529        nan 0.79364241        nan        nan\n",
            " 0.76981612 0.79643975 0.79643975 0.79643975 0.80905712 0.76981612\n",
            "        nan        nan        nan        nan        nan 0.78943662\n",
            "        nan 0.78943662 0.80905712 0.77122457        nan 0.79364241\n",
            "        nan        nan 0.80905712 0.79643975 0.79643975 0.79643975\n",
            " 0.8062989  0.81187402        nan        nan        nan        nan\n",
            "        nan 0.78943662        nan 0.78943662 0.80489045 0.81187402\n",
            "        nan 0.79364241        nan        nan 0.81052426 0.79643975\n",
            " 0.79643975 0.79643975 0.803482   0.81050469        nan        nan\n",
            "        nan        nan        nan 0.78943662        nan 0.78943662\n",
            " 0.803482   0.81050469        nan 0.79364241        nan        nan\n",
            " 0.72208529 0.79364241 0.79364241 0.79364241 0.72631064 0.72208529\n",
            "        nan        nan        nan        nan        nan 0.78943662\n",
            "        nan 0.78943662 0.72631064 0.72208529        nan 0.79364241\n",
            "        nan        nan 0.77122457 0.79364241 0.79364241 0.79364241\n",
            " 0.80905712 0.76981612        nan        nan        nan        nan\n",
            "        nan 0.78943662        nan 0.78943662 0.80905712 0.77122457\n",
            "        nan 0.79364241        nan        nan 0.80905712 0.79364241\n",
            " 0.79364241 0.79364241 0.8062989  0.81187402        nan        nan\n",
            "        nan        nan        nan 0.78943662        nan 0.78943662\n",
            " 0.80489045 0.81187402        nan 0.79364241        nan        nan\n",
            " 0.80911581 0.79364241 0.79364241 0.79364241 0.803482   0.81050469\n",
            "        nan        nan        nan        nan        nan 0.78943662\n",
            "        nan 0.78943662 0.803482   0.81050469]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best hyper-parameters:\n",
            " {'C': 0.25, 'max_iter': 2500, 'penalty': 'l2', 'solver': 'saga'}\n",
            "\n",
            "Best accuracy: 81.18740219092334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the testing dataset\n",
        "test = pd.read_csv (r\"titanic_test.csv\")\n",
        "x_new = test.iloc[:, [1, 3, 4, 5, 6, 8, 10]].values\n",
        "x_df = pd.DataFrame (x_new, columns = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'])\n",
        "print (\"\\nFeatures:\\n\", x_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZzQ2xFbyszb",
        "outputId": "9beac28c-993d-4f31-cd39-68d53cf14af4"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Features:\n",
            "     Pclass     Sex   Age SibSp Parch     Fare Embarked\n",
            "0        3    male  34.5     0     0   7.8292        Q\n",
            "1        3  female  47.0     1     0      7.0        S\n",
            "2        2    male  62.0     0     0   9.6875        Q\n",
            "3        3    male  27.0     0     0   8.6625        S\n",
            "4        3  female  22.0     1     1  12.2875        S\n",
            "..     ...     ...   ...   ...   ...      ...      ...\n",
            "413      3    male   NaN     0     0     8.05        S\n",
            "414      1  female  39.0     0     0    108.9        C\n",
            "415      3    male  38.5     0     0     7.25        S\n",
            "416      3    male   NaN     0     0     8.05        S\n",
            "417      3    male   NaN     1     1  22.3583        C\n",
            "\n",
            "[418 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"\\nMissing values in different features:\\n\", x_df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7dhB07t53ba",
        "outputId": "2476597c-9257-4c8b-97d8-321c40dae3cc"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing values in different features:\n",
            " Pclass       0\n",
            "Sex          0\n",
            "Age         86\n",
            "SibSp        0\n",
            "Parch        0\n",
            "Fare         1\n",
            "Embarked     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling the missing values\n",
        "#One hot encoding the categorical features\n",
        "x_new = ct.transform (x_new)"
      ],
      "metadata": {
        "id": "IDSSm5CFzrKX"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_new = embarked.transform (x_new)\n",
        "x_df_new = pd.DataFrame (x_new)\n",
        "print (\"\\nPreprocessed features:\\n\", x_df_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBHMcPQp7dHW",
        "outputId": "1301cdd2-1804-4005-8936-28db2068545d"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Preprocessed features:\n",
            "       0    1    2     3        4    5    6    7    8    9  10 11\n",
            "0    0.0  1.0  0.0  34.5   7.8292  0.0  0.0  1.0  0.0  1.0  0  0\n",
            "1    0.0  0.0  1.0  47.0      7.0  0.0  0.0  1.0  1.0  0.0  1  0\n",
            "2    0.0  1.0  0.0  62.0   9.6875  0.0  1.0  0.0  0.0  1.0  0  0\n",
            "3    0.0  0.0  1.0  27.0   8.6625  0.0  0.0  1.0  0.0  1.0  0  0\n",
            "4    0.0  0.0  1.0  22.0  12.2875  0.0  0.0  1.0  1.0  0.0  1  1\n",
            "..   ...  ...  ...   ...      ...  ...  ...  ...  ...  ... .. ..\n",
            "413  0.0  0.0  1.0  24.0     8.05  0.0  0.0  1.0  0.0  1.0  0  0\n",
            "414  1.0  0.0  0.0  39.0    108.9  1.0  0.0  0.0  1.0  0.0  0  0\n",
            "415  0.0  0.0  1.0  38.5     7.25  0.0  0.0  1.0  0.0  1.0  0  0\n",
            "416  0.0  0.0  1.0  24.0     8.05  0.0  0.0  1.0  0.0  1.0  0  0\n",
            "417  1.0  0.0  0.0  24.0  22.3583  0.0  0.0  1.0  0.0  1.0  1  1\n",
            "\n",
            "[418 rows x 12 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Standardizing the dataset\n",
        "x_new[:, [3, 11]] = sc.transform (x_new[:, [3, 11]])\n",
        "x_test_df = pd.DataFrame (x_new)\n",
        "print (\"\\nStandardised features:\\n\", x_test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "940fcb1f-e003-43b5-bd59-1da2466c10af",
        "id": "DsioLiko65yT"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Standardised features:\n",
            "       0    1    2         3        4    5    6    7    8    9  10        11\n",
            "0    0.0  1.0  0.0  0.443746   7.8292  0.0  0.0  1.0  0.0  1.0  0  -0.47741\n",
            "1    0.0  0.0  1.0  1.385072      7.0  0.0  0.0  1.0  1.0  0.0  1  -0.47741\n",
            "2    0.0  1.0  0.0  2.514664   9.6875  0.0  1.0  0.0  0.0  1.0  0  -0.47741\n",
            "3    0.0  0.0  1.0  -0.12105   8.6625  0.0  0.0  1.0  0.0  1.0  0  -0.47741\n",
            "4    0.0  0.0  1.0 -0.497581  12.2875  0.0  0.0  1.0  1.0  0.0  1  0.740927\n",
            "..   ...  ...  ...       ...      ...  ...  ...  ...  ...  ... ..       ...\n",
            "413  0.0  0.0  1.0 -0.346969     8.05  0.0  0.0  1.0  0.0  1.0  0  -0.47741\n",
            "414  1.0  0.0  0.0  0.782623    108.9  1.0  0.0  0.0  1.0  0.0  0  -0.47741\n",
            "415  0.0  0.0  1.0   0.74497     7.25  0.0  0.0  1.0  0.0  1.0  0  -0.47741\n",
            "416  0.0  0.0  1.0 -0.346969     8.05  0.0  0.0  1.0  0.0  1.0  0  -0.47741\n",
            "417  1.0  0.0  0.0 -0.346969  22.3583  0.0  0.0  1.0  0.0  1.0  1  0.740927\n",
            "\n",
            "[418 rows x 12 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression (C = 0.25, max_iter = 2500, penalty = 'l2', solver = 'saga', random_state = 0)\n",
        "lr.fit (x, y)\n",
        "y_pred = lr.predict (x_new)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKw8ZxMi_2Nz",
        "outputId": "81bc2094-4b27-4ec0-c9fb-b5a4a55e9104"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
              "       1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "       1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "       0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
              "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
              "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    }
  ]
}
