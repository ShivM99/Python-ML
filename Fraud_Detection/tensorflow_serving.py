# -*- coding: utf-8 -*-
"""TensorFlow_Serving.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GZ1xKFtyc5P0NHMwNGIF_RHCi9IX0u8z
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import IsolationForest
import tensorflow as tf
from keras.models import Sequential, load_model
from keras.layers import Dense
from sklearn.metrics import f1_score, confusion_matrix, accuracy_score

ann_model = load_model ('/content/ANN.h5')

import os
export_path = './content/ANNmodel/1'

tf.keras.models.save_model (ann_model, export_path, overwrite=True, include_optimizer=True, save_format=None, signatures=None, options=None)

print ('\nSaved model:')
!ls -l {export_path}

!saved_model_cli show --dir ./content/ANNmodel/1 --all

import sys
# We need sudo prefix if not on a Google Colab.
if 'google.colab' not in sys.modules:
  SUDO_IF_NEEDED = 'sudo'
else:
  SUDO_IF_NEEDED = ''

!echo "deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal" | {SUDO_IF_NEEDED} tee /etc/apt/sources.list.d/tensorflow-serving.list && \
curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | {SUDO_IF_NEEDED} apt-key add -
!{SUDO_IF_NEEDED} apt update

!wget 'http://storage.googleapis.com/tensorflow-serving-apt/pool/tensorflow-model-server-2.8.0/t/tensorflow-model-server/tensorflow-model-server_2.8.0_all.deb'
!dpkg -i tensorflow-model-server_2.8.0_all.deb
!pip3 install tensorflow-serving-api==2.8.0

os.environ["MODEL_DIR"] = './content/ANNmodel/'

# Deploying our model on the server using TensorFlow Serving
!nohup tensorflow_model_server --rest_api_port=8501 --model_name=ann_model --model_base_path="/content/ANNmodel" >server.log 2>&1

!tail server.log

import requests
import json
# Define input data for prediction
input_data = {"instances": [{"type":'TRANSFER', "amount":1000, "oldBalDonor":1500, "newBalDonor":500, "oldBalRecipient":2000, "newBalRecipient":3000}]}
# Send HTTP POST request to TensorFlow Serving
response = requests.post ('http://localhost:8501/v1/models/ann_model:predict', json=input_data)
# Parse prediction result
predictions = json.loads (response.text)['predictions']